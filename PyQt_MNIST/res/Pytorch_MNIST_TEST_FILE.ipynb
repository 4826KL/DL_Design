{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce13a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba03997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 64\n",
    "INPUT_SIZE = 28 \n",
    "LR = 0.01\n",
    "DOWNLOAD_MNIST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d803a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNNnet, self).__init__()\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=64,  \n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.out = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)\n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b624fc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mnist digits dataset\n",
    "if not (os.path.exists('./mnist/')) or not os.listdir('./mnist/'):\n",
    "    DOWNLOAD_MNIST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e54bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 9912422/9912422 [00:46<00:00, 211334.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 733808.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:05<00:00, 275799.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 加载训练数据\n",
    "train_data = dsets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=DOWNLOAD_MNIST\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af5c8115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot one example\n",
    "print(train_data.data.size())     # (60000, 28, 28)\n",
    "print(train_data.targets.size())   # (60000)\n",
    "plt.imshow(train_data.data[0].numpy(), cmap='gray')\n",
    "plt.title('%i' % train_data.targets[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5afa4420",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c35a4a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNnet(\n",
      "  (rnn): LSTM(28, 64, batch_first=True)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 加载测试数据\n",
    "test_data = dsets.MNIST(root='./mnist/',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor()\n",
    "                        )\n",
    "test_x = test_data.data.type(torch.FloatTensor)[:2000]/255.\n",
    "test_y = test_data.targets.numpy()[:2000]\n",
    "\n",
    "rnn = RNNnet()\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0f360fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d9aac48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 2.3180 | test accuracy: 0.12\n",
      "Epoch:  0 | train loss: 0.9422 | test accuracy: 0.58\n",
      "Epoch:  0 | train loss: 0.9379 | test accuracy: 0.68\n",
      "Epoch:  0 | train loss: 0.7059 | test accuracy: 0.83\n",
      "Epoch:  0 | train loss: 0.3940 | test accuracy: 0.85\n",
      "Epoch:  0 | train loss: 0.4765 | test accuracy: 0.88\n",
      "Epoch:  0 | train loss: 0.3025 | test accuracy: 0.88\n",
      "Epoch:  0 | train loss: 0.3197 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.1880 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.2370 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss: 0.3781 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss: 0.4899 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.2359 | test accuracy: 0.93\n",
      "Epoch:  0 | train loss: 0.0758 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss: 0.1473 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss: 0.1262 | test accuracy: 0.93\n",
      "Epoch:  0 | train loss: 0.0683 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss: 0.1864 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.1377 | test accuracy: 0.95\n",
      "Epoch:  1 | train loss: 0.1838 | test accuracy: 0.94\n",
      "Epoch:  1 | train loss: 0.1679 | test accuracy: 0.96\n",
      "Epoch:  1 | train loss: 0.1146 | test accuracy: 0.94\n",
      "Epoch:  1 | train loss: 0.1186 | test accuracy: 0.94\n",
      "Epoch:  1 | train loss: 0.2083 | test accuracy: 0.95\n",
      "Epoch:  1 | train loss: 0.0728 | test accuracy: 0.96\n",
      "Epoch:  1 | train loss: 0.0431 | test accuracy: 0.95\n",
      "Epoch:  1 | train loss: 0.2390 | test accuracy: 0.96\n",
      "Epoch:  1 | train loss: 0.1738 | test accuracy: 0.95\n",
      "Epoch:  1 | train loss: 0.2404 | test accuracy: 0.96\n",
      "Epoch:  1 | train loss: 0.0986 | test accuracy: 0.94\n",
      "Epoch:  1 | train loss: 0.0346 | test accuracy: 0.96\n",
      "Epoch:  1 | train loss: 0.0987 | test accuracy: 0.96\n",
      "Epoch:  1 | train loss: 0.0685 | test accuracy: 0.96\n",
      "Epoch:  1 | train loss: 0.2158 | test accuracy: 0.96\n",
      "Epoch:  1 | train loss: 0.0538 | test accuracy: 0.97\n",
      "Epoch:  1 | train loss: 0.0398 | test accuracy: 0.95\n",
      "Epoch:  1 | train loss: 0.1954 | test accuracy: 0.97\n",
      "Epoch:  1 | train loss: 0.2181 | test accuracy: 0.95\n",
      "Epoch:  2 | train loss: 0.1465 | test accuracy: 0.96\n",
      "Epoch:  2 | train loss: 0.0152 | test accuracy: 0.96\n",
      "Epoch:  2 | train loss: 0.0166 | test accuracy: 0.96\n",
      "Epoch:  2 | train loss: 0.0814 | test accuracy: 0.96\n",
      "Epoch:  2 | train loss: 0.3024 | test accuracy: 0.97\n",
      "Epoch:  2 | train loss: 0.1690 | test accuracy: 0.97\n",
      "Epoch:  2 | train loss: 0.0450 | test accuracy: 0.96\n",
      "Epoch:  2 | train loss: 0.2025 | test accuracy: 0.95\n",
      "Epoch:  2 | train loss: 0.1571 | test accuracy: 0.96\n",
      "Epoch:  2 | train loss: 0.0459 | test accuracy: 0.97\n",
      "Epoch:  2 | train loss: 0.0468 | test accuracy: 0.97\n",
      "Epoch:  2 | train loss: 0.1099 | test accuracy: 0.97\n",
      "Epoch:  2 | train loss: 0.1592 | test accuracy: 0.97\n",
      "Epoch:  2 | train loss: 0.0957 | test accuracy: 0.96\n",
      "Epoch:  2 | train loss: 0.0510 | test accuracy: 0.96\n",
      "Epoch:  2 | train loss: 0.0239 | test accuracy: 0.97\n",
      "Epoch:  2 | train loss: 0.0257 | test accuracy: 0.97\n",
      "Epoch:  2 | train loss: 0.1179 | test accuracy: 0.96\n",
      "Epoch:  2 | train loss: 0.2678 | test accuracy: 0.97\n",
      "Epoch:  3 | train loss: 0.1012 | test accuracy: 0.97\n",
      "Epoch:  3 | train loss: 0.0219 | test accuracy: 0.97\n",
      "Epoch:  3 | train loss: 0.0642 | test accuracy: 0.97\n",
      "Epoch:  3 | train loss: 0.1435 | test accuracy: 0.97\n",
      "Epoch:  3 | train loss: 0.0595 | test accuracy: 0.97\n",
      "Epoch:  3 | train loss: 0.0149 | test accuracy: 0.96\n",
      "Epoch:  3 | train loss: 0.1214 | test accuracy: 0.97\n",
      "Epoch:  3 | train loss: 0.0375 | test accuracy: 0.97\n",
      "Epoch:  3 | train loss: 0.1036 | test accuracy: 0.97\n",
      "Epoch:  3 | train loss: 0.0643 | test accuracy: 0.96\n",
      "Epoch:  3 | train loss: 0.0171 | test accuracy: 0.98\n",
      "Epoch:  3 | train loss: 0.0416 | test accuracy: 0.97\n",
      "Epoch:  3 | train loss: 0.1593 | test accuracy: 0.97\n",
      "Epoch:  3 | train loss: 0.1279 | test accuracy: 0.97\n",
      "Epoch:  3 | train loss: 0.1387 | test accuracy: 0.97\n",
      "Epoch:  3 | train loss: 0.0205 | test accuracy: 0.97\n",
      "Epoch:  3 | train loss: 0.0450 | test accuracy: 0.96\n",
      "Epoch:  3 | train loss: 0.1241 | test accuracy: 0.96\n",
      "Epoch:  3 | train loss: 0.0946 | test accuracy: 0.96\n",
      "Epoch:  4 | train loss: 0.0961 | test accuracy: 0.97\n",
      "Epoch:  4 | train loss: 0.0069 | test accuracy: 0.97\n",
      "Epoch:  4 | train loss: 0.0431 | test accuracy: 0.97\n",
      "Epoch:  4 | train loss: 0.1441 | test accuracy: 0.97\n",
      "Epoch:  4 | train loss: 0.0337 | test accuracy: 0.97\n",
      "Epoch:  4 | train loss: 0.1613 | test accuracy: 0.97\n",
      "Epoch:  4 | train loss: 0.0336 | test accuracy: 0.97\n",
      "Epoch:  4 | train loss: 0.0709 | test accuracy: 0.97\n",
      "Epoch:  4 | train loss: 0.0088 | test accuracy: 0.97\n",
      "Epoch:  4 | train loss: 0.0608 | test accuracy: 0.97\n",
      "Epoch:  4 | train loss: 0.2300 | test accuracy: 0.98\n",
      "Epoch:  4 | train loss: 0.0797 | test accuracy: 0.97\n",
      "Epoch:  4 | train loss: 0.0591 | test accuracy: 0.98\n",
      "Epoch:  4 | train loss: 0.0806 | test accuracy: 0.98\n",
      "Epoch:  4 | train loss: 0.0397 | test accuracy: 0.98\n",
      "Epoch:  4 | train loss: 0.0519 | test accuracy: 0.97\n",
      "Epoch:  4 | train loss: 0.0769 | test accuracy: 0.96\n",
      "Epoch:  4 | train loss: 0.1353 | test accuracy: 0.97\n",
      "Epoch:  4 | train loss: 0.0434 | test accuracy: 0.97\n",
      "Epoch:  5 | train loss: 0.0155 | test accuracy: 0.97\n",
      "Epoch:  5 | train loss: 0.1389 | test accuracy: 0.97\n",
      "Epoch:  5 | train loss: 0.1135 | test accuracy: 0.97\n",
      "Epoch:  5 | train loss: 0.0442 | test accuracy: 0.98\n",
      "Epoch:  5 | train loss: 0.0180 | test accuracy: 0.98\n",
      "Epoch:  5 | train loss: 0.0097 | test accuracy: 0.98\n",
      "Epoch:  5 | train loss: 0.0653 | test accuracy: 0.97\n",
      "Epoch:  5 | train loss: 0.0871 | test accuracy: 0.97\n",
      "Epoch:  5 | train loss: 0.1192 | test accuracy: 0.97\n",
      "Epoch:  5 | train loss: 0.0101 | test accuracy: 0.98\n",
      "Epoch:  5 | train loss: 0.0228 | test accuracy: 0.98\n",
      "Epoch:  5 | train loss: 0.0587 | test accuracy: 0.97\n",
      "Epoch:  5 | train loss: 0.0143 | test accuracy: 0.98\n",
      "Epoch:  5 | train loss: 0.0212 | test accuracy: 0.98\n",
      "Epoch:  5 | train loss: 0.0368 | test accuracy: 0.98\n",
      "Epoch:  5 | train loss: 0.1160 | test accuracy: 0.97\n",
      "Epoch:  5 | train loss: 0.0565 | test accuracy: 0.98\n",
      "Epoch:  5 | train loss: 0.0324 | test accuracy: 0.97\n",
      "Epoch:  5 | train loss: 0.0457 | test accuracy: 0.97\n",
      "Epoch:  6 | train loss: 0.0108 | test accuracy: 0.97\n",
      "Epoch:  6 | train loss: 0.0172 | test accuracy: 0.98\n",
      "Epoch:  6 | train loss: 0.0106 | test accuracy: 0.98\n",
      "Epoch:  6 | train loss: 0.0140 | test accuracy: 0.97\n",
      "Epoch:  6 | train loss: 0.0934 | test accuracy: 0.98\n",
      "Epoch:  6 | train loss: 0.0157 | test accuracy: 0.97\n",
      "Epoch:  6 | train loss: 0.0485 | test accuracy: 0.97\n",
      "Epoch:  6 | train loss: 0.0034 | test accuracy: 0.98\n",
      "Epoch:  6 | train loss: 0.0367 | test accuracy: 0.98\n",
      "Epoch:  6 | train loss: 0.0121 | test accuracy: 0.98\n",
      "Epoch:  6 | train loss: 0.0472 | test accuracy: 0.98\n",
      "Epoch:  6 | train loss: 0.0674 | test accuracy: 0.98\n",
      "Epoch:  6 | train loss: 0.0676 | test accuracy: 0.97\n",
      "Epoch:  6 | train loss: 0.0241 | test accuracy: 0.97\n",
      "Epoch:  6 | train loss: 0.0532 | test accuracy: 0.97\n",
      "Epoch:  6 | train loss: 0.1399 | test accuracy: 0.98\n",
      "Epoch:  6 | train loss: 0.0154 | test accuracy: 0.98\n",
      "Epoch:  6 | train loss: 0.0415 | test accuracy: 0.98\n",
      "Epoch:  6 | train loss: 0.0730 | test accuracy: 0.97\n",
      "Epoch:  7 | train loss: 0.1462 | test accuracy: 0.97\n",
      "Epoch:  7 | train loss: 0.1040 | test accuracy: 0.97\n",
      "Epoch:  7 | train loss: 0.0139 | test accuracy: 0.97\n",
      "Epoch:  7 | train loss: 0.0066 | test accuracy: 0.97\n",
      "Epoch:  7 | train loss: 0.0344 | test accuracy: 0.96\n",
      "Epoch:  7 | train loss: 0.0274 | test accuracy: 0.97\n",
      "Epoch:  7 | train loss: 0.2542 | test accuracy: 0.97\n",
      "Epoch:  7 | train loss: 0.0106 | test accuracy: 0.97\n",
      "Epoch:  7 | train loss: 0.0046 | test accuracy: 0.97\n",
      "Epoch:  7 | train loss: 0.0533 | test accuracy: 0.96\n",
      "Epoch:  7 | train loss: 0.1148 | test accuracy: 0.95\n",
      "Epoch:  7 | train loss: 0.0974 | test accuracy: 0.97\n",
      "Epoch:  7 | train loss: 0.0766 | test accuracy: 0.97\n",
      "Epoch:  7 | train loss: 0.0651 | test accuracy: 0.97\n",
      "Epoch:  7 | train loss: 0.0440 | test accuracy: 0.97\n",
      "Epoch:  7 | train loss: 0.2009 | test accuracy: 0.97\n",
      "Epoch:  7 | train loss: 0.0495 | test accuracy: 0.96\n",
      "Epoch:  7 | train loss: 0.0889 | test accuracy: 0.97\n",
      "Epoch:  7 | train loss: 0.1138 | test accuracy: 0.97\n",
      "Epoch:  8 | train loss: 0.0352 | test accuracy: 0.96\n",
      "Epoch:  8 | train loss: 0.0320 | test accuracy: 0.97\n",
      "Epoch:  8 | train loss: 0.0216 | test accuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8 | train loss: 0.0344 | test accuracy: 0.97\n",
      "Epoch:  8 | train loss: 0.0835 | test accuracy: 0.98\n",
      "Epoch:  8 | train loss: 0.0644 | test accuracy: 0.97\n",
      "Epoch:  8 | train loss: 0.0267 | test accuracy: 0.97\n",
      "Epoch:  8 | train loss: 0.0650 | test accuracy: 0.98\n",
      "Epoch:  8 | train loss: 0.0508 | test accuracy: 0.98\n",
      "Epoch:  8 | train loss: 0.0318 | test accuracy: 0.97\n",
      "Epoch:  8 | train loss: 0.0054 | test accuracy: 0.97\n",
      "Epoch:  8 | train loss: 0.0419 | test accuracy: 0.97\n",
      "Epoch:  8 | train loss: 0.2232 | test accuracy: 0.97\n",
      "Epoch:  8 | train loss: 0.0123 | test accuracy: 0.98\n",
      "Epoch:  8 | train loss: 0.0572 | test accuracy: 0.97\n",
      "Epoch:  8 | train loss: 0.0307 | test accuracy: 0.98\n",
      "Epoch:  8 | train loss: 0.0509 | test accuracy: 0.97\n",
      "Epoch:  8 | train loss: 0.0901 | test accuracy: 0.97\n",
      "Epoch:  8 | train loss: 0.0228 | test accuracy: 0.98\n",
      "Epoch:  9 | train loss: 0.1165 | test accuracy: 0.97\n",
      "Epoch:  9 | train loss: 0.1855 | test accuracy: 0.97\n",
      "Epoch:  9 | train loss: 0.0138 | test accuracy: 0.98\n",
      "Epoch:  9 | train loss: 0.1821 | test accuracy: 0.98\n",
      "Epoch:  9 | train loss: 0.0474 | test accuracy: 0.97\n",
      "Epoch:  9 | train loss: 0.0182 | test accuracy: 0.97\n",
      "Epoch:  9 | train loss: 0.2247 | test accuracy: 0.98\n",
      "Epoch:  9 | train loss: 0.1049 | test accuracy: 0.98\n",
      "Epoch:  9 | train loss: 0.1305 | test accuracy: 0.98\n",
      "Epoch:  9 | train loss: 0.0048 | test accuracy: 0.98\n",
      "Epoch:  9 | train loss: 0.1109 | test accuracy: 0.98\n",
      "Epoch:  9 | train loss: 0.0146 | test accuracy: 0.97\n",
      "Epoch:  9 | train loss: 0.0461 | test accuracy: 0.96\n",
      "Epoch:  9 | train loss: 0.0623 | test accuracy: 0.97\n",
      "Epoch:  9 | train loss: 0.1199 | test accuracy: 0.97\n",
      "Epoch:  9 | train loss: 0.0734 | test accuracy: 0.97\n",
      "Epoch:  9 | train loss: 0.0938 | test accuracy: 0.97\n",
      "Epoch:  9 | train loss: 0.1420 | test accuracy: 0.98\n",
      "Epoch:  9 | train loss: 0.0040 | test accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):\n",
    "        b_x = b_x.view(-1, 28, 28) \n",
    "        output = rnn(b_x)\n",
    "        loss = loss_func(output, b_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "        if step % 50 == 0:\n",
    "            test_output = rnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "            accuracy = float((pred_y == test_y).astype(int).sum()) / float(test_y.size)\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy(), '| test accuracy: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dad57ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "# print 10 predictions from test data\n",
    "test_output = rnn(test_x[:10].view(-1, 28, 28))\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10], 'real number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52cb23e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning2023",
   "language": "python",
   "name": "deeplearning2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
